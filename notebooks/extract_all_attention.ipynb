{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": "# 单层注意力分析 / Single-Layer Attention Analysis\n\n## 工作流程 / Workflow\n\n**Step 1:** 运行注意力提取脚本 / Run the attention extraction script:\n```bash\nbash experiments/extract_attention.sh ./Wan2.1-T2V-1.3B 20 cache\n```\n\n**Step 2:** 更新下方 `DATA_PATH` 指向生成的 `.pt` 文件 / Update `DATA_PATH` below\n\n**Step 3:** 运行所有 cell 生成图表 / Run all cells to generate plots\n\n---\n\n绘制两张图 / Two plots:\n1. **2D 热力图**: Query Frame × Key Frame，3×4 网格显示 12 个 head\n2. **Per-Head Grid**: 最后一个 block 对各帧的注意力柱状图"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "plt.rcParams.update({\n",
    "        \"svg.fonttype\": \"none\",\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": [\"Arial\", \"DejaVu Sans\", \"Helvetica\"],\n",
    "        \"font.size\": 11,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"axes.titlesize\": 13,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"figure.dpi\": 150,\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"savefig.pad_inches\": 0.1,  \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# 配置 / Configuration\n# ============================================================\n# 运行 extract_attention.sh 后，将 DATA_PATH 指向生成的 .pt 文件\n# After running extract_attention.sh, point DATA_PATH to the generated .pt file\n#\n# Example:\n#   bash experiments/extract_attention.sh ./Wan2.1-T2V-1.3B 20 cache\n#   -> generates cache/layer20.pt\n\nDATA_PATH = \"../cache/layer20.pt\"\nSAVE_DIR = \"attention_analysis\"\nSAVE_SVG = True\n\n# 检查文件是否存在\nimport os\nif not os.path.exists(DATA_PATH):\n    print(f\"⚠️  Warning: {DATA_PATH} not found!\")\n    print(\"   Run: bash experiments/extract_attention.sh <ckpt_dir> <layer_index>\")\nelse:\n    print(f\"✓ Found: {DATA_PATH}\")"
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(DATA_PATH, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Layer: {data['layer_index']}\")\n",
    "print(f\"Prompt: {data.get('prompt', 'N/A')}\")\n",
    "print(f\"Num frames (saved): {data.get('num_frames', 'N/A')}\")\n",
    "print(f\"Num heads: {data.get('num_heads', 'N/A')}\")\n",
    "print(f\"Block sizes: {data.get('block_sizes', 'N/A')}\")\n",
    "print(f\"Last block Q frames (saved): {data.get('last_block_query_frames', 'N/A')}\")\n",
    "\n",
    "# 加载数据\n",
    "layer_idx = data['layer_index']\n",
    "num_heads = data['num_heads']\n",
    "\n",
    "# 更新保存目录（使用层索引）\n",
    "SAVE_DIR_LAYER = os.path.join(SAVE_DIR, f\"layer{layer_idx}\")\n",
    "\n",
    "# 完整的 frame×frame 注意力矩阵（latent 帧）\n",
    "full_frame_attn = data['full_frame_attention'].float().numpy()  # [num_heads, Q, K]\n",
    "latent_num_frames = full_frame_attn.shape[1]\n",
    "print(f\"\\nFull attention shape (latent): {full_frame_attn.shape}\")\n",
    "print(f\"Range: [{full_frame_attn.min():.4f}, {full_frame_attn.max():.4f}]\")\n",
    "\n",
    "# ============================================================\n",
    "# Frame View Config\n",
    "# ============================================================\n",
    "# 注意：模型在时间维度有下采样（vae_stride[0]=4），所以 latent 帧数通常小于原始帧数。\n",
    "# 如果你想按原始帧 (e.g. 21) 来看，把 USE_ORIG_FRAMES=True 并设置 ORIG_NUM_FRAMES。\n",
    "USE_ORIG_FRAMES = True\n",
    "ORIG_NUM_FRAMES = data.get('orig_num_frames', 21)  # 如果不同，请手动改\n",
    "TEMPORAL_STRIDE = data.get('vae_stride_t', 4)  # t2v-1.3B 为 4\n",
    "\n",
    "if USE_ORIG_FRAMES and ORIG_NUM_FRAMES is not None:\n",
    "    orig_indices = np.arange(ORIG_NUM_FRAMES, dtype=int)\n",
    "    orig_to_latent = np.minimum(orig_indices // TEMPORAL_STRIDE, latent_num_frames - 1)\n",
    "    display_full_frame_attn = full_frame_attn[:, orig_to_latent][:, :, orig_to_latent]\n",
    "    display_num_frames = ORIG_NUM_FRAMES\n",
    "    display_frame_indices = orig_indices.tolist()\n",
    "    print(f\"\\nUsing expanded attention for original frames: {ORIG_NUM_FRAMES} (stride={TEMPORAL_STRIDE}).\")\n",
    "else:\n",
    "    display_full_frame_attn = full_frame_attn\n",
    "    display_num_frames = latent_num_frames\n",
    "    display_frame_indices = list(range(latent_num_frames))\n",
    "    print(f\"\\nUsing latent-frame attention: {latent_num_frames} frames.\")\n",
    "\n",
    "# 选择要看的 query 帧（按原始帧索引）\n",
    "QUERY_FRAMES = [18, 19, 20] if display_num_frames >= 21 else list(range(max(display_num_frames - 3, 0), display_num_frames))\n",
    "last_block_q_frames = QUERY_FRAMES\n",
    "last_block_attn = display_full_frame_attn[:, QUERY_FRAMES, :].mean(axis=1)  # [num_heads, K]\n",
    "\n",
    "print(f\"Last block query frames (display): {last_block_q_frames}\")\n",
    "print(f\"Last block attention shape: {last_block_attn.shape}\")\n",
    "print(f\"Save directory: {SAVE_DIR_LAYER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot1-header",
   "metadata": {},
   "source": [
    "## 图1: 2D 热力图 (Query Frame × Key Frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot1-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 图1: 2D 热力图 - 每个 head 一张小图\n",
    "# X-axis: Key Frame Index\n",
    "# Y-axis: Query Frame Index\n",
    "# Layout: 3×4 grid for 12 heads\n",
    "# ============================================================\n",
    "\n",
    "ncols = 4\n",
    "nrows = math.ceil(num_heads / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 全局 colorbar 范围（对称，便于 RdBu_r 显示）\n",
    "vmax = max(abs(display_full_frame_attn.min()), abs(display_full_frame_attn.max()))\n",
    "vmin = -vmax\n",
    "\n",
    "for h in range(num_heads):\n",
    "    ax = axes[h]\n",
    "    attn_map = display_full_frame_attn[h]  # [Q, K]\n",
    "    \n",
    "    im = ax.imshow(\n",
    "        attn_map,\n",
    "        cmap=\"RdBu_r\",\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        interpolation=\"nearest\"\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Head {h}\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Key Frame\", fontsize=9)\n",
    "    ax.set_ylabel(\"Query Frame\", fontsize=9)\n",
    "    \n",
    "    # 设置刻度\n",
    "    tick_pos = [0, display_num_frames // 2, display_num_frames - 1]\n",
    "    ax.set_xticks(tick_pos)\n",
    "    ax.set_xticklabels(tick_pos)\n",
    "    ax.set_yticks(tick_pos)\n",
    "    ax.set_yticklabels(tick_pos)\n",
    "\n",
    "# 隐藏多余的子图\n",
    "for k in range(num_heads, len(axes)):\n",
    "    axes[k].axis(\"off\")\n",
    "\n",
    "# 添加 colorbar\n",
    "fig.subplots_adjust(right=0.92)\n",
    "cbar_ax = fig.add_axes([0.94, 0.15, 0.02, 0.7])\n",
    "cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "cbar.set_label(\"Attention Logits\", fontsize=11)\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"Layer {layer_idx}: 2D Attention Maps (All Heads)\\n\"\n",
    "    f\"Query Frames: 0-{display_num_frames-1}, Key Frames: 0-{display_num_frames-1}\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.02\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.92, 0.98])\n",
    "\n",
    "if SAVE_SVG:\n",
    "    os.makedirs(SAVE_DIR_LAYER, exist_ok=True)\n",
    "    save_path = os.path.join(SAVE_DIR_LAYER, f\"layer{layer_idx}_2d_heatmap_all_heads.svg\")\n",
    "    plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "    print(f\"Saved: {save_path}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot2-header",
   "metadata": {},
   "source": [
    "## 图2: Per-Head Grid (最后一个 block 对各帧的注意力)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot2-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 图2: Per-Head Grid 柱状图\n",
    "# 显示 QUERY_FRAMES 对各 key frame 的注意力（默认 18-20）\n",
    "# ============================================================\n",
    "\n",
    "key_indices = np.arange(display_num_frames)\n",
    "\n",
    "ncols = 4\n",
    "nrows = math.ceil(num_heads / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(14, 3 * nrows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "BAR_COLOR = sns.color_palette(\"colorblind\")[0]\n",
    "\n",
    "for h in range(num_heads):\n",
    "    ax = axes[h]\n",
    "    head = last_block_attn[h]  # [K]\n",
    "    \n",
    "    # 计算 sink score (首帧 - 中间帧均值)\n",
    "    first = head[0]\n",
    "    middle = head[1:-1].mean() if len(head) > 2 else head.mean()\n",
    "    sink_score = first - middle\n",
    "    \n",
    "    ax.bar(key_indices, head, alpha=0.85, width=0.8, color=BAR_COLOR)\n",
    "    ax.plot(key_indices, head, \"o-\", color=\"black\", linewidth=1, markersize=2)\n",
    "    ax.set_title(f\"H{h} (sink={sink_score:.2f})\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if len(key_indices) > 10:\n",
    "        ax.set_xticks([0, len(key_indices) // 2, len(key_indices) - 1])\n",
    "\n",
    "for k in range(num_heads, len(axes)):\n",
    "    axes[k].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"Layer {layer_idx}: Per-Head Attention Distribution\\n\"\n",
    "    f\"Query: frames {last_block_q_frames}\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.00 + (0.01 * nrows),\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if SAVE_SVG:\n",
    "    os.makedirs(SAVE_DIR_LAYER, exist_ok=True)\n",
    "    save_path = os.path.join(SAVE_DIR_LAYER, f\"layer{layer_idx}_perhead_grid.svg\")\n",
    "    plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "    print(f\"Saved: {save_path}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats-header",
   "metadata": {},
   "source": [
    "## 统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stats-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Layer 20 Statistics\n",
      "============================================================\n",
      "Diagonal mean (self-attention): 7.9511\n",
      "First frame mean (sink): 1.4547\n",
      "\n",
      "Per-Head Statistics (last block):\n",
      "  H 0: first=  1.787, mid=  1.454, last=  2.680, sink= +0.333\n",
      "  H 1: first=  1.240, mid=  0.186, last=  5.461, sink= +1.055\n",
      "  H 2: first=  4.270, mid=  0.990, last=  7.281, sink= +3.279\n",
      "  H 3: first=  3.805, mid=  0.452, last=  7.125, sink= +3.352\n",
      "  H 4: first=  3.789, mid=  3.106, last=  2.883, sink= +0.683\n",
      "  H 5: first=  2.662, mid=  0.583, last=  6.707, sink= +2.079\n",
      "  H 6: first=  4.168, mid=  3.730, last=  5.309, sink= +0.438\n",
      "  H 7: first=  6.180, mid=  1.992, last= 10.375, sink= +4.188\n",
      "  H 8: first=  0.476, mid= -0.379, last=  4.203, sink= +0.855\n",
      "  H 9: first=  1.579, mid=  0.468, last=  3.674, sink= +1.111\n",
      "  H10: first=  2.215, mid=  1.685, last=  3.797, sink= +0.530\n",
      "  H11: first=  1.619, mid=  0.062, last=  5.547, sink= +1.557\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(f\"Layer {layer_idx} Statistics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 全局统计\n",
    "diag = np.array([display_full_frame_attn[h, i, i] for h in range(num_heads) for i in range(display_num_frames)])\n",
    "diag_mean = diag.mean()\n",
    "first_col = display_full_frame_attn[:, :, 0]\n",
    "first_col_mean = first_col[first_col != 0].mean() if (first_col != 0).any() else 0\n",
    "\n",
    "print(f\"Diagonal mean (self-attention): {diag_mean:.4f}\")\n",
    "print(f\"First frame mean (sink): {first_col_mean:.4f}\")\n",
    "\n",
    "print(\"\\nPer-Head Statistics (selected frames):\")\n",
    "for h in range(num_heads):\n",
    "    head = last_block_attn[h]\n",
    "    first = head[0]\n",
    "    middle = head[1:-1].mean() if len(head) > 2 else head.mean()\n",
    "    last = head[-1]\n",
    "    sink = first - middle\n",
    "    \n",
    "    print(f\"  H{h:2d}: first={first:7.3f}, mid={middle:7.3f}, last={last:7.3f}, sink={sink:+7.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}